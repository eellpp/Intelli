<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Corpus Analysis With R</title>
  <meta name="description" content="The tm package provides functionality for exploratory analysis on  text corpus.The nature of text corpus has a big effect on the data modeling. Some of the t...">

  <link rel="stylesheet" href="/intelli/css/main.css">
  <link rel="canonical" href="http://localhost:4000/intelli/2014/12/24/corpus-analysis-with-r.html">
  <link rel="alternate" type="application/rss+xml" title="IntelliSignals" href="http://localhost:4000/intelli/feed.xml">
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">
    <div class="site-title">
	<a href="/intelli/" style="font-size: 42px;">IntelliSignals</a>
	<h2 style="display: inline;font-size: 16px;margin-bottom: 0px;">BigData, Analytics and Cloud</h2>
     </div>

    <nav class="site-nav">
      <a href="#" class="menu-icon">
        <svg viewBox="0 0 18 15">
          <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>

      <div class="trigger">
        
	  
	  
		  
		  <a class="page-link" href="/intelli/about/">About</a>
		  
	  
        
	  
	  
		  
		  <a class="page-link" href="/intelli/archive/">Archive</a>
		  
	  
        
	  
	  
		  
	  
        
	  
	  
		  
	  
        
	  
	  
		  
	  
        
	  
	  
		  
	  
        
      </div>
    </nav>

  </div>

</header>


    <div class="page-content">
      <div class="wrapper">
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title" itemprop="name headline">Corpus Analysis With R</h1>
    <p class="post-meta">
	<time datetime="2014-12-24T00:00:00+08:00" itemprop="datePublished">Dec 24, 2014
 	</time>
	
		

		
		|
		<a href="
				http://localhost:4000//intelli
			/tag/R/" >R</a>
		
		<a href="
				http://localhost:4000//intelli
			/tag/analytics/" >analytics</a>
		
		<a href="
				http://localhost:4000//intelli
			/tag/nlp/" >nlp</a>
		 
		
	
    </p>
  </header>

  <div class="post-content" itemprop="articleBody">
    <p>The tm package provides functionality for exploratory analysis on  text corpus.
The nature of text corpus has a big effect on the data modeling. Some of the text corpus that i have worked on in past includes</p>

<ul>
  <li>Structured news feeds</li>
  <li>Unstructured html news webpages</li>
  <li>Web page Comments</li>
  <li>Tweets</li>
  <li>Posts on news sharing forum corpus</li>
  <li>Emails</li>
</ul>

<p>After the text preprocessing stage all of these would be a list of documents. But the nature of data in each of these vary a lot. HTML pages have to go through rigorous content processing to filter out unwanted content. Comments and tweets will have short text where each of them will have there own semantic keywords. Similarly a corpus of emails will have to handled in specific ways.</p>

<p>After the preprocessing stage we are ready to explore the corpus to further find the relationships between the docs and understand the deeper meaning</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c"># create the text corpus which tm can operate</span>
 corpus &lt;- Corpus<span class="o">(</span> textVectors<span class="o">)</span>

<span class="c"># do the required transformations on the corpus</span>
 corpus &lt;- tm_map<span class="o">(</span>corpus,stripWhitespace<span class="o">)</span>
 corpus &lt;- tm_map<span class="o">(</span>corpus,content_transformer<span class="o">(</span>tolower<span class="o">))</span>
 corpus &lt;- tm_map<span class="o">(</span>corpus,removeNumbers<span class="o">)</span>
 corpus &lt;- tm_map<span class="o">(</span>corpus,removePunctuation,preserve_intra_word_dashes <span class="o">=</span> TRUE<span class="o">)</span>
<span class="c"># instead of using the default stopwords you can add your own stopwords</span>
 corpus &lt;- tm_map<span class="o">(</span>corpus,removeWords, stopwords<span class="o">(</span><span class="s2">"english"</span><span class="o">))</span>
 corpus &lt;- tm_map<span class="o">(</span>corpus, PlainTextDocument<span class="o">)</span>
<span class="c"># you can create custom transformation by supplying your function to the tm_map function</span>

<span class="c">#Create a term document matrix from the corpus to do numerical bag of words computation of the corpus</span>
tdm &lt;- TermDocumentMatrix<span class="o">(</span>corpus<span class="o">)</span>

<span class="c">#Or  Instead of frequency you can use a tfidf score as the weighting functions</span>
tdm &lt;- TermDocumentMatrix<span class="o">(</span>corpus,control <span class="o">=</span> list<span class="o">(</span>weighting <span class="o">=</span> <span class="k">function</span><span class="o">(</span>x<span class="o">)</span>
    weightTfIdf<span class="o">(</span>x, normalize <span class="o">=</span> FALSE<span class="o">)))</span></code></pre></figure>

<p>Now that we have converted a corpus into a numerical matrix we can do all kind of computation on it. The term document matrix is a sparse matrix since many of the words would be unique to certain docs. Use the inspect function to look into the details of this matrix</p>

<p>inspect(tdm)</p>

<p>Some operations you could do on this</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c"># subset the matrix only by the words contained in a tagset</span>
tdm.onlytags &lt;- tdm[rownames<span class="o">(</span>tdm<span class="o">)</span> %in% tagset<span class="nv">$tag</span>, <span class="o">]</span>

<span class="c"># create a sorted list of top terms</span>
top_terms &lt;- sort<span class="o">(</span>sapply<span class="o">(</span>rownames<span class="o">(</span>tdm<span class="o">)</span>, <span class="k">function</span><span class="o">(</span>x<span class="o">)</span> sum<span class="o">(</span>tdm[c<span class="o">(</span>x<span class="o">)</span>, <span class="o">]))</span>, decreasing <span class="o">=</span> TRUE<span class="o">)</span>
top_terms &lt;-  sort<span class="o">(</span>rowSums<span class="o">(</span>tdm<span class="o">))</span>

<span class="c"># create a term document matrix from the top terms in corpus</span>
tdm[c<span class="o">(</span>names<span class="o">(</span>top_terms<span class="o">))</span>, <span class="o">]</span></code></pre></figure>

<p>Since this is numerical matrix, you can slice and dice it to your hearts content.</p>

<p>Some other functionality provided by tm package</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c"># remove sparse terms from term document matrix</span>
removeSparseTerms<span class="o">(</span>dtm, 0.1<span class="o">)</span>

<span class="c"># find the freq terms above a threshold</span>
ï¿¼findFreqTerms<span class="o">(</span>dtm, <span class="nv">lowfreq</span><span class="o">=</span>1000<span class="o">)</span>

<span class="c"># find Associations with a word with correlation limit</span>
findAssocs<span class="o">(</span>dtm, <span class="s2">"data"</span>, <span class="nv">corlimit</span><span class="o">=</span>0.6<span class="o">)</span></code></pre></figure>

<p>Often we want to do sentence level analyis of a give corpus. The text could be a article, book or a corpus where breaking it into sentences and then doing a word level analysis into the sentence structure could give a better understanding of the document.</p>

<p>For doing these kind of NLP analysis we use the packages NLP, OpenNLP and RWeka</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">install.packages<span class="o">(</span>c<span class="o">(</span><span class="s2">"NLP"</span>, <span class="s2">"openNLP"</span>, <span class="s2">"RWeka"</span>, <span class="s2">"qdap"</span><span class="o">))</span>
<span class="c"># download the OpenNLP models</span>
install.packages<span class="o">(</span><span class="s2">"openNLPmodels.en"</span>, repos <span class="o">=</span> <span class="s2">"http://datacube.wu.ac.at/"</span>, <span class="nb">type</span> <span class="o">=</span> <span class="s2">"source"</span><span class="o">)</span></code></pre></figure>

<p>The package openNLPmodels.en contains the following models for identifying these entities from text :</p>

<ul>
  <li>Date</li>
  <li>Location</li>
  <li>Money</li>
  <li>Organization</li>
  <li>Percentage</li>
  <li>Person</li>
  <li>Time</li>
</ul>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">library<span class="o">(</span>NLP<span class="o">)</span>
library<span class="o">(</span>openNLP<span class="o">)</span>
library<span class="o">(</span>RWeka<span class="o">)</span>
library<span class="o">(</span>magrittr<span class="o">)</span>
<span class="c"># read the plain text dataset</span>
<span class="c"># http://www.gutenberg.org/cache/epub/1342/pg1342.txt</span>
lines &lt;- readLines<span class="o">(</span><span class="s2">"pride_and_prejudice.txt"</span><span class="o">)</span>
doc &lt;- as.String<span class="o">(</span>paste<span class="o">(</span>lines, collapse <span class="o">=</span> <span class="s2">" "</span><span class="o">))</span>

<span class="c"># create the sentence annotator</span>
sent_ann &lt;- Maxent_Sent_Token_Annotator<span class="o">()</span>
<span class="c"># create the word annotator</span>
word_ann &lt;- Maxent_Word_Token_Annotator<span class="o">()</span>
<span class="c"># create person annotator</span>
person_ann &lt;- Maxent_Entity_Annotator<span class="o">(</span>kind <span class="o">=</span> <span class="s2">"person"</span><span class="o">)</span>
<span class="c"># create location annotator</span>
location_ann &lt;- Maxent_Entity_Annotator<span class="o">(</span>kind <span class="o">=</span> <span class="s2">"location"</span><span class="o">)</span>
<span class="c"># create organization annotator</span>
organization_ann &lt;- Maxent_Entity_Annotator<span class="o">(</span>kind <span class="o">=</span> <span class="s2">"organization"</span><span class="o">)</span>
<span class="c"># create the annotation pipeline</span>
doc_annotations &lt;- annotate<span class="o">(</span>doc, list<span class="o">(</span>sent_ann, word_ann,person_ann,location_ann,organization_ann<span class="o">))</span>
doc_ann &lt;- AnnotatedPlainTextDocument<span class="o">(</span>doc, doc_annotations<span class="o">)</span></code></pre></figure>

<p>Now we can extract the various entities from the extracted document for further analysis</p>


  </div>

</article>

      </div>
    </div>

    <footer class="site-footer">

  <div class="wrapper">


    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li>IntelliSignals</li>
          <li><a href="mailto:contact@intellisignals.com">contact@intellisignals.com</a></li>
        </ul>
      </div>

      <div class="footer-col footer-col-2">
        <ul class="social-media-list">
          

          
        </ul>
      </div>

    </div>

  </div>

</footer>


  </body>

</html>
